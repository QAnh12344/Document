def info_sup_contrastive_loss(z1, z2, y, tau=0.2, sup_weight=1.0, batch_size=2048):
    device = z1.device
    N = z1.size(0)
    loss_all = []

    for start in range(0, N, batch_size):
        end = min(start + batch_size, N)
        z1_b = safe_normalize(z1[start:end])
        z2_b = safe_normalize(z2[start:end])
        y_b = y[start:end]

        # ----- InfoNCE -----
        logits_info = torch.matmul(z1_b, z2_b.T) / tau
        labels_info = torch.arange(end-start, device=device)
        loss_info = F.cross_entropy(logits_info, labels_info)

        # ----- SupCon -----
        z_b = torch.cat([z1_b, z2_b], dim=0)  # (2B, D)
        y_b2 = y_b.repeat(2)
        sim = torch.matmul(z_b, z_b.T) / tau

        mask = torch.eye(2*(end-start), dtype=torch.bool, device=device)
        sim.masked_fill_(mask, -1e9)

        pos_mask = (y_b2.unsqueeze(0) == y_b2.unsqueeze(1)) & (~mask)
        exp_sim = torch.exp(sim)
        numerator = (exp_sim * pos_mask).sum(dim=1)
        denominator = exp_sim.sum(dim=1)
        loss_sup = -torch.log((numerator + 1e-8) / (denominator + 1e-8))
        loss_sup = loss_sup.mean()

        # combine
        loss_all.append(loss_info + sup_weight * loss_sup)

    return torch.mean(torch.stack(loss_all))






import torch
import torch.nn.functional as F

def safe_normalize(z, dim=1, eps=1e-6):
    """
    Convert to float if needed, handle empty, NaN/Inf, then normalize.
    Returns normalized tensor with same device.
    """
    if not torch.is_tensor(z):
        raise TypeError("safe_normalize expects a torch.Tensor")

    # ensure float
    if not z.dtype.is_floating_point:
        z = z.float()

    # shape check: expect 2D (N, D)
    if z.ndim != 2:
        raise ValueError(f"safe_normalize expects 2D tensor (N, D). Got ndim={z.ndim}, shape={z.shape}")

    # replace NaN/Inf (if any)
    if torch.isnan(z).any() or torch.isinf(z).any():
        z = torch.nan_to_num(z, nan=0.0, posinf=1e6, neginf=-1e6)

    # if a row is all zeros, add tiny noise to avoid zero-norm
    row_norm = torch.linalg.vector_norm(z, dim=1)
    zero_rows = (row_norm == 0)
    if zero_rows.any():
        z[zero_rows] = z[zero_rows] + (torch.randn_like(z[zero_rows]) * eps)

    # finally normalize
    z = F.normalize(z, dim=dim)
    return z

# usage
z2 = safe_normalize(z2, dim=1)



def info_nce_loss_minibatch(z1, z2, batch_size=4096, tau=0.2):
    N = z1.size(0)
    loss_all = []

    for start in range(0, N, batch_size):
        end = min(start + batch_size, N)

        z1_b = F.normalize(z1[start:end], dim=1)
        z2_b = F.normalize(z2[start:end], dim=1)

        # negatives chỉ trong batch → không OOM
        sim = torch.matmul(z1_b, z2_b.T) / tau

        labels = torch.arange(end - start, device=z1.device)

        loss = F.cross_entropy(sim, labels)
        loss_all.append(loss)

    return torch.mean(torch.stack(loss_all))




import torch
import torch.nn.functional as F

def prototype_contrastive_loss(z, y, tau=0.2, eps=1e-8):
    """
    z: [N, d]   node embeddings
    y: [N]      labels
    tau: temperature
    """

    # ---- 1. Normalize ----
    z = F.normalize(z, dim=1)

    # ---- 2. Compute prototypes by class ----
    classes = torch.unique(y)
    prototypes = []

    for c in classes:
        proto = z[y == c].mean(dim=0)
        prototypes.append(proto)

    prototypes = torch.stack(prototypes)                     # [C, d]
    prototypes = F.normalize(prototypes, dim=1).detach()     # <-- detach quan trọng

    # ---- 3. Cosine sim: node vs all prototypes ----
    sim = torch.matmul(z, prototypes.T) / tau                # [N, C]

    # ---- 4. Map labels → prototype index ----
    mapping = {c.item(): i for i, c in enumerate(classes)}
    target = torch.tensor([mapping[label.item()] for label in y],
                          device=z.device)

    # ---- 5. Class-balanced loss (fix imbalance) ----
    counts = torch.tensor(
        [ (y == c).sum().item() for c in classes ],
        device=z.device, dtype=torch.float
    )
    weights = 1.0 / (counts + eps)                           # inverse freq
    weights = weights / weights.sum()                       # normalize

    # ---- 6. Cross entropy with class weights ----
    loss = F.cross_entropy(sim, target, weight=weights)

    return loss





import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import HypergraphConv
from sklearn.model_selection import train_test_split
from collections import Counter

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ---------- Load .pt ----------
data = torch.load("your_hypergraph.pt")
# expect: data.x [N, F], data.y [N], data.edge_index [2, E] (node, hyperedge)
x = data.x
y = data.y
edge_index = data.edge_index  # [2, E]

# ---------- train/test split (stratified) ----------
all_idx = torch.arange(x.size(0))
train_idx_np, test_idx_np = train_test_split(all_idx.numpy(), test_size=0.2, stratify=y.numpy(), random_state=42)
train_idx = torch.tensor(train_idx_np, dtype=torch.long)
test_idx = torch.tensor(test_idx_np, dtype=torch.long)

# ---------- helper: build subgraph with reindexing ----------
def build_subgraph(node_idx, edge_index):
    """
    node_idx: 1D tensor of original node indices to keep
    edge_index: [2, E] (node, hyperedge)
    returns:
      new_x_idx_map: dict old->new
      sub_edge_index: [2, E_sub] with node ids remapped 0..n-1
      keep_node_idx (tensor): original indices in same order as mapping
    """
    node_idx = node_idx.cpu()
    n_keep = node_idx.numel()
    old2new = -torch.ones(edge_index[0].max().item()+1, dtype=torch.long)
    old2new[node_idx] = torch.arange(n_keep, dtype=torch.long)
    # mask edges columns where node in train
    mask = torch.isin(edge_index[0], node_idx)
    ei = edge_index[:, mask]
    # group by hyperedge id: for each hyperedge collect nodes that are in node_idx
    he_ids = torch.unique(ei[1])
    new_cols = []
    for he in he_ids:
        nodes = ei[0][ei[1]==he]
        nodes_new = old2new[nodes]
        # drop hyperedge if less than 2 nodes after filter
        if nodes_new.numel() < 2:
            continue
        he_new_col = torch.stack([nodes_new, torch.full((nodes_new.size(0),), he, dtype=torch.long)], dim=0)
        new_cols.append(he_new_col)
    if len(new_cols)==0:
        return old2new, torch.empty((2,0), dtype=torch.long), node_idx
    sub_edge_index = torch.cat(new_cols, dim=1)
    return old2new, sub_edge_index, node_idx

old2new_train, edge_index_train, train_keep = build_subgraph(train_idx, edge_index)
# edge_index_train nodes are remapped 0..N_train-1 but hyperedge ids remain original ids (not contiguous) - that's ok

# build x_train, y_train in remapped order
x_train = x[train_keep].to(device)
y_train = y[train_keep].to(device)

x_test = x[test_idx].to(device)
y_test = y[test_idx].to(device)

edge_index_train = edge_index_train.to(device)

# ---------- identify rare classes in train set ----------
label_counts = Counter(y_train.tolist())
threshold = 10
rare_classes = [c for c, cnt in label_counts.items() if cnt < threshold]
rare_mask = torch.isin(y_train, torch.tensor(rare_classes, device=y_train.device))
rare_nodes_local_idx = rare_mask.nonzero(as_tuple=True)[0]  # indices in 0..N_train-1
# collect hyperedges that involve rare nodes (hyperedge ids are original he ids)
rare_hyperedges = torch.unique(edge_index_train[1][torch.isin(edge_index_train[0], rare_nodes_local_idx)]).to(device)

# ---------- augmentation helpers (operate on remapped train subgraph) ----------
def feature_jitter_subset(x_sub, nodes_local_idx, sigma=0.02):
    x_aug = x_sub.clone()
    if nodes_local_idx.numel() > 0:
        x_aug[nodes_local_idx] = x_aug[nodes_local_idx] + torch.randn_like(x_aug[nodes_local_idx]) * sigma
    return x_aug

def drop_nodes_in_hyperedge_sub(edge_index_sub, rare_hyperedges_ids, drop_rate=0.3):
    new_cols = []
    he_ids = torch.unique(edge_index_sub[1])
    for he in he_ids:
        cols = (edge_index_sub[1] == he)
        nodes = edge_index_sub[0, cols]
        if he in rare_hyperedges_ids:
            keep_mask = torch.rand(nodes.size(0), device=nodes.device) > drop_rate
            if keep_mask.sum() < 2:
                # ensure at least 2
                keep_idx = torch.arange(nodes.size(0), device=nodes.device)
                keep_mask[keep_idx[:2]] = True
            nodes = nodes[keep_mask]
        # skip if <2 nodes
        if nodes.numel() < 2:
            continue
        he_cols = torch.stack([nodes, torch.full((nodes.size(0),), he, dtype=torch.long, device=nodes.device)], dim=0)
        new_cols.append(he_cols)
    if len(new_cols)==0:
        return torch.empty((2,0), dtype=torch.long, device=edge_index_sub.device)
    return torch.cat(new_cols, dim=1)

# ---------- Encoder ----------
class HyperGCL_Encoder(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super().__init__()
        self.conv1 = HypergraphConv(in_dim, hid_dim)
        self.conv2 = HypergraphConv(hid_dim, out_dim)
    def forward(self, x_local, edge_index_local):
        x = F.relu(self.conv1(x_local, edge_index_local))
        x = self.conv2(x, edge_index_local)
        return x

# ---------- prototype contrastive loss (robust) ----------
def prototype_contrastive_loss(z, y, tau=0.5, eps=1e-6):
    # z: [N, d] normalized inside
    # y: [N] local labels (may contain subset of classes)
    device = z.device
    classes = torch.unique(y)
    prototypes = []
    valid_classes = []
    for c in classes:
        mask = (y == c)
        if mask.sum() == 0:
            continue
        prot = z[mask].mean(dim=0)
        prototypes.append(prot)
        valid_classes.append(c)
    if len(prototypes) == 0:
        return torch.tensor(0.0, device=device, requires_grad=True)
    prototypes = torch.stack(prototypes, dim=0)
    # normalize
    z_n = F.normalize(z, dim=1)
    p_n = F.normalize(prototypes, dim=1)
    sim = torch.matmul(z_n, p_n.T) / tau
    # map y -> index in valid_classes
    c2i = {int(c.item()): idx for idx, c in enumerate(valid_classes)}
    target = torch.tensor([c2i[int(v.item())] for v in y], device=device)
    loss = F.cross_entropy(sim, target)
    return loss

# ---------- training ----------
in_dim = x_train.size(1)
hid_dim = 64
out_dim = 64
encoder = HyperGCL_Encoder(in_dim, hid_dim, out_dim).to(device)
opt = torch.optim.Adam(encoder.parameters(), lr=1e-3, weight_decay=1e-5)

epochs = 100
for epoch in range(epochs):
    encoder.train()
    # create two augmented views only on train subgraph
    x_v1 = feature_jitter_subset(x_train, rare_nodes_local_idx, sigma=0.02)
    e_v1 = drop_nodes_in_hyperedge_sub(edge_index_train, rare_hyperedges, drop_rate=0.3)
    x_v2 = feature_jitter_subset(x_train, rare_nodes_local_idx, sigma=0.02)
    e_v2 = drop_nodes_in_hyperedge_sub(edge_index_train, rare_hyperedges, drop_rate=0.3)

    # If augmentation removed all edges, fallback to original
    if e_v1.size(1) == 0:
        e_v1 = edge_index_train
    if e_v2.size(1) == 0:
        e_v2 = edge_index_train

    z1 = encoder(x_v1, e_v1)
    z2 = encoder(x_v2, e_v2)

    # combine
    z = torch.cat([z1, z2], dim=0)
    y_comb = torch.cat([y_train, y_train], dim=0)

    # normalize embeddings before proto loss
    z = F.normalize(z, dim=1)
    loss = prototype_contrastive_loss(z, y_comb, tau=0.5)

    opt.zero_grad()
    loss.backward()
    opt.step()

    if epoch % 10 == 0:
        print(f"Epoch {epoch} loss {loss.item():.4f}")

# ---------- Linear probe evaluation (train a simple classifier on frozen encoder) ----------
encoder.eval()
with torch.no_grad():
    # encode full train graph using original train edge_index (no augmentation)
    z_train_full = encoder(x_train, edge_index_train)
    z_test_full = encoder(x_test, edge_index_train)  # WARNING: if test hyperedges refer to nodes outside train, prefer building full graph encoder

# train small linear classifier on top of z_train_full
clf = nn.Linear(z_train_full.size(1), int(y.max().item())+1).to(device)
clf_opt = torch.optim.Adam(clf.parameters(), lr=1e-3, weight_decay=1e-5)
for it in range(200):
    clf.train()
    logits = clf(z_train_full)
    loss_clf = F.cross_entropy(logits, y_train)
    clf_opt.zero_grad()
    loss_clf.backward()
    clf_opt.step()
# evaluate
clf.eval()
with torch.no_grad():
    logits_test = clf(z_test_full)
    pred = logits_test.argmax(dim=1)
    acc = (pred == y_test).float().mean().item()
print("Linear probe test accuracy:", acc)





import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import HypergraphConv

# --------------------------
# 1️⃣ Load data
# --------------------------
data = torch.load("your_hypergraph.pt")
# data.edge_index: [2, num_edges] node↔hyperedge
# data.x: node features [num_nodes, num_features]
# data.y: node labels [num_nodes]

# Identify rare classes
threshold = 10
from collections import Counter
label_counts = Counter(data.y.tolist())
rare_classes = [c for c, cnt in label_counts.items() if cnt < threshold]
rare_nodes_idx = torch.tensor([i for i, label in enumerate(data.y) if label in rare_classes])
rare_hyperedges_idx = torch.unique(data.edge_index[1][torch.isin(data.edge_index[0], rare_nodes_idx)])

# --------------------------
# 2️⃣ Augmentation functions
# --------------------------
def feature_jitter(x, nodes_idx, sigma=0.02):
    x_aug = x.clone()
    x_aug[nodes_idx] += torch.randn_like(x_aug[nodes_idx]) * sigma
    return x_aug

def drop_nodes_in_hyperedge(edge_index, rare_hyperedges_idx, drop_rate=0.3):
    new_edge_list = []
    for he in torch.unique(edge_index[1]):
        nodes_in_he = edge_index[0, edge_index[1] == he]
        if he in rare_hyperedges_idx:
            keep_mask = torch.rand(len(nodes_in_he)) > drop_rate
            if keep_mask.sum() < 2:
                keep_mask[:2] = True
            nodes_in_he = nodes_in_he[keep_mask]
        he_indices = torch.full((len(nodes_in_he),), he, dtype=torch.long)
        new_edge_list.append(torch.stack([nodes_in_he, he_indices], dim=0))
    return torch.cat(new_edge_list, dim=1)

# --------------------------
# 3️⃣ Hypergraph Encoder
# --------------------------
class HyperGCL_Encoder(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super().__init__()
        self.conv1 = HypergraphConv(in_dim, hid_dim)
        self.conv2 = HypergraphConv(hid_dim, out_dim)
    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x

# --------------------------
# 4️⃣ Prototype Contrastive Loss
# --------------------------
def prototype_contrastive_loss(z, y, tau=0.5):
    classes = torch.unique(y)
    prototypes = torch.stack([z[y==c].mean(dim=0) for c in classes])
    z = F.normalize(z, dim=1)
    prototypes = F.normalize(prototypes, dim=1)
    sim = torch.matmul(z, prototypes.T) / tau
    label_to_idx = {c.item(): idx for idx, c in enumerate(classes)}
    target = torch.tensor([label_to_idx[label.item()] for label in y], device=z.device)
    loss = F.cross_entropy(sim, target)
    return loss

# --------------------------
# 5️⃣ Training step (example)
# --------------------------
in_dim = data.x.size(1)
hid_dim = 64
out_dim = 64
encoder = HyperGCL_Encoder(in_dim, hid_dim, out_dim)

optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)

for epoch in range(50):
    # Augment rare class
    x_view1 = feature_jitter(data.x, rare_nodes_idx, sigma=0.02)
    edge_view1 = drop_nodes_in_hyperedge(data.edge_index, rare_hyperedges_idx, drop_rate=0.3)
    
    x_view2 = feature_jitter(data.x, rare_nodes_idx, sigma=0.02)
    edge_view2 = drop_nodes_in_hyperedge(data.edge_index, rare_hyperedges_idx, drop_rate=0.3)
    
    # Encode views
    z1 = encoder(x_view1, edge_view1)
    z2 = encoder(x_view2, edge_view2)
    
    # Combine embeddings
    z = torch.cat([z1, z2], dim=0)
    y = torch.cat([data.y, data.y], dim=0)
    
    # Prototype contrastive loss
    loss = prototype_contrastive_loss(z, y, tau=0.5)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if epoch % 5 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")





import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import HypergraphConv

# -----------------------
# 1. Encoder + Projection
# -----------------------
class HyperEncoder(nn.Module):
    def __init__(self, in_dim=64, hid_dim=128):
        super().__init__()
        self.conv1 = HypergraphConv(in_dim, hid_dim)
        self.conv2 = HypergraphConv(hid_dim, hid_dim)

    def forward(self, x, hyperedge):
        he_idx, he_id = hyperedge
        x = self.conv1(x, he_idx, he_id)
        x = F.relu(x)
        x = self.conv2(x, he_idx, he_id)
        return x

class Projector(nn.Module):
    def __init__(self, in_dim=128, out_dim=64):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(in_dim, in_dim),
            nn.ReLU(),
            nn.Linear(in_dim, out_dim)
        )

    def forward(self, z):
        return self.mlp(z)

# -----------------------
# 2. Contrastive Loss (InfoNCE)
# -----------------------
def contrastive_loss(z1, z2, tau=0.2):
    z1 = F.normalize(z1, dim=-1)
    z2 = F.normalize(z2, dim=-1)

    sim = z1 @ z2.t() / tau
    labels = torch.arange(sim.size(0)).long().cuda()
    return F.cross_entropy(sim, labels)

# -----------------------
# 3. Hypergraph Augmentation
# -----------------------
def augment(hyperedge_index, drop_rate=0.1):
    M = hyperedge_index.size(1)
    keep = int(M * (1 - drop_rate))
    idx = torch.randperm(M)[:keep]
    return hyperedge_index[:, idx], idx

# -----------------------
# 4. Training Loop (Batch Hyperedges)
# -----------------------
def train_contrastive(x, hyperedge_index, num_hyperedge, hyperedge_ptr, epochs=3, batch_size=1000):
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    encoder = HyperEncoder().to(device)
    proj = Projector().to(device)
    opt = torch.optim.Adam(list(encoder.parameters()) + list(proj.parameters()), lr=1e-3)

    x = x.to(device)

    for epoch in range(epochs):
        for h in range(0, num_hyperedge, batch_size):
            s = hyperedge_ptr[h]
            e = hyperedge_ptr[min(h + batch_size, num_hyperedge)]

            he_idx = hyperedge_index[:, s:e]
            he_id  = torch.arange(he_idx.size(1))

            # View 1
            he1_idx, _ = augment(he_idx)
            he1_id = torch.arange(he1_idx.size(1))
            he1 = (he1_idx.to(device), he1_id.to(device))

            # View 2
            he2_idx, _ = augment(he_idx)
            he2_id = torch.arange(he2_idx.size(1))
            he2 = (he2_idx.to(device), he2_id.to(device))

            # Encode
            z1 = encoder(x, he1)
            z2 = encoder(x, he2)

            # Projection
            p1 = proj(z1)
            p2 = proj(z2)

            # Loss
            loss = contrastive_loss(p1, p2)

            opt.zero_grad()
            loss.backward()
            opt.step()

        print(f"Epoch {epoch}  loss={loss.item():.4f}")

# -----------------------
# 5. Example Usage
# -----------------------
if __name__ == "__main__":
    # giả sử data bạn có:
    # x: (1694050, 64)
    # hyperedge_index: (2, M)
    # num_hyperedge = 60000
    # hyperedge_ptr: list start index của từng hyperedge
    x = torch.randn(1694050, 64)
    num_hyperedge = 60000
    hyperedge_index = torch.randint(0, 1694050, (2, 300000))  # ví dụ
    hyperedge_ptr = torch.linspace(0, hyperedge_index.size(1), steps=num_hyperedge + 1).long()

    train_contrastive(x, hyperedge_index, num_hyperedge, hyperedge_ptr)





import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import HypergraphConv

########################################
# 1) HyperGCN Model
########################################

class HyperGCN(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super().__init__()
        self.conv1 = HypergraphConv(in_dim, hid_dim)
        self.conv2 = HypergraphConv(hid_dim, out_dim)

    def forward(self, x, hyperedge_index):
        h = F.relu(self.conv1(x, hyperedge_index))
        z = self.conv2(h, hyperedge_index)
        return z

########################################
# 2) Augmentation Module (HyperGCL)
########################################

class AugmentModule:
    """HyperGCL augmentations"""

    # ---------- node drop ----------
    def node_drop(self, data: Data, drop_prob: float):
        x = data.x.clone()
        mask = torch.rand(x.size(0)) > drop_prob
        x = x * mask.unsqueeze(1)
        return self._clone_data(data, x=x)

    # ---------- feature mask ----------
    def feature_mask(self, data: Data, mask_prob: float):
        x = data.x.clone()
        mask = torch.rand_like(x) > mask_prob
        x = x * mask
        return self._clone_data(data, x=x)

    # ---------- hyperedge drop ----------
    def hyperedge_drop(self, data: Data, drop_prob: float):
        he = data.hyperedge_index
        num_edges = he[1].max().item() + 1
        mask = torch.rand(num_edges) > drop_prob
        keep = mask[he[1]]
        new_he = he[:, keep]
        return self._clone_data(data, hyperedge_index=new_he)

    # ---------- hyperedge perturb ----------
    def hyperedge_perturbation(self, data: Data, add_ratio=0.05, remove_ratio=0.05):
        he = data.hyperedge_index.clone()
        N = data.x.size(0)
        E = he[1].max().item() + 1

        keep = torch.rand(he.size(1)) > remove_ratio
        new_he = he[:, keep]

        num_add = int(he.size(1) * add_ratio)
        if num_add > 0:
            add_nodes = torch.randint(0, N, (num_add,))
            add_edges = torch.randint(0, E, (num_add,))
            add_he = torch.stack([add_nodes, add_edges], dim=0)
            new_he = torch.cat([new_he, add_he], dim=1)

        return self._clone_data(data, hyperedge_index=new_he)

    # ---------- helpers ----------
    def _clone_data(self, data: Data, x=None, hyperedge_index=None):
        return Data(
            x = x if x is not None else data.x.clone(),
            y = data.y,
            hyperedge_index = hyperedge_index if hyperedge_index is not None else data.hyperedge_index,
            train_mask = data.train_mask,
            val_mask = data.val_mask,
            test_mask = data.test_mask,
        )

    # ---------- pipeline ----------
    def apply(self, data, pipeline):
        d = data
        for (name, params) in pipeline:
            if name == "node_drop":
                d = self.node_drop(d, **params)
            elif name == "feature_mask":
                d = self.feature_mask(d, **params)
            elif name == "hyperedge_drop":
                d = self.hyperedge_drop(d, **params)
            elif name == "hyperedge_perturbation":
                d = self.hyperedge_perturbation(d, **params)
        return d

    def make_two_views(self, data, aug1, aug2):
        return self.apply(data, aug1), self.apply(data, aug2)


########################################
# 3) NT-Xent Contrastive Loss (SimCLR)
########################################

def contrastive_loss(z1, z2, temperature=0.5):
    z1 = F.normalize(z1, dim=1)
    z2 = F.normalize(z2, dim=1)

    B = z1.size(0)
    sim = torch.mm(z1, z2.t()) / temperature
    labels = torch.arange(B).long().to(z1.device)
    return F.cross_entropy(sim, labels)


########################################
# 4) Full Training Function
########################################

def run_training(model, data, aug_module, epochs=200, lr=1e-3,
                 temperature=0.5, alpha=0.5, device='cpu'):

    model = model.to(device)
    data = data.to(device)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    # define augmentations
    aug1 = [
        ("node_drop", {"drop_prob": 0.2}),
        ("feature_mask", {"mask_prob": 0.2})
    ]
    aug2 = [
        ("hyperedge_drop", {"drop_prob": 0.2}),
        ("hyperedge_perturbation", {"add_ratio": 0.05, "remove_ratio": 0.05})
    ]

    for epoch in range(epochs):

        # ------- contrastive views -------
        v1, v2 = aug_module.make_two_views(data, aug1, aug2)
        v1 = v1.to(device)
        v2 = v2.to(device)

        model.train()
        z1 = model(v1.x, v1.hyperedge_index)
        z2 = model(v2.x, v2.hyperedge_index)

        loss_cl = contrastive_loss(z1, z2, temperature)

        z = model(data.x, data.hyperedge_index)
        loss_sup = F.cross_entropy(z[data.train_mask], data.y[data.train_mask])

        loss = alpha * loss_sup + (1 - alpha) * loss_cl

        opt.zero_grad()
        loss.backward()
        opt.step()

        if (epoch + 1) % 20 == 0:
            print(f"[Epoch {epoch+1}] Loss_sup={loss_sup.item():.4f}  Loss_cl={loss_cl.item():.4f}")

    # evaluate on test
    model.eval()
    out = model(data.x, data.hyperedge_index)
    pred = out.argmax(dim=1)
    test_acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean().item()

    print("=====================================")
    print(f" Test Accuracy: {test_acc:.4f}")
    print("=====================================")

    return model


########################################
# 5) Example synthetic data
########################################

if __name__ == "__main__":
    torch.manual_seed(42)

    x = torch.randn(100, 16)                     # node features
    y = torch.randint(0, 2, (100,))             # labels classification

    # random hypergraph H: N=100 nodes, E=20 hyperedges
    he_nodes = torch.randint(0, 100, (300,))
    he_edges = torch.randint(0, 20, (300,))
    hyperedge_index = torch.stack([he_nodes, he_edges], dim=0)

    data = Data(
        x=x,
        y=y,
        hyperedge_index=hyperedge_index,
        train_mask=torch.zeros(100, dtype=torch.bool).bernoulli(0.6),
        val_mask=torch.zeros(100, dtype=torch.bool).bernoulli(0.2),
        test_mask=torch.zeros(100, dtype=torch.bool).bernoulli(0.2)
    )

    model = HyperGCN(in_dim=16, hid_dim=32, out_dim=2)
    aug = AugmentModule()

    run_training(
        model=model,
        data=data,
        aug_module=aug,
        epochs=200,
        lr=1e-3,
        alpha=0.7
    )





import torch
import torch.nn as nn
from torch_geometric.nn import HypergraphConv

# Example HyperGCN model
class HyperGCN(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim):
        super().__init__()
        self.conv1 = HypergraphConv(in_dim, hid_dim)
        self.conv2 = HypergraphConv(hid_dim, out_dim)

    def forward(self, x, hyperedge_index):
        x = self.conv1(x, hyperedge_index)
        x = torch.relu(x)
        x = self.conv2(x, hyperedge_index)
        return x

# Example training loop

def train(model, data, epochs=200, lr=1e-3):
    model.train()
    opt = torch.optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.CrossEntropyLoss()

    x = data.x
    y = data.y
    hyperedge_index = data.hyperedge_index
    train_mask = data.train_mask

    for epoch in range(epochs):
        opt.zero_grad()
        out = model(x, hyperedge_index)
        loss = loss_fn(out[train_mask], y[train_mask])
        loss.backward()
        opt.step()

        if epoch % 20 == 0:
            print(f"Epoch {epoch} | Loss: {loss.item():.4f}")

# Usage:
# from torch_geometric.data import Data
# data = Data(x=node_features, y=labels, hyperedge_index=hyperedge_index, train_mask=train_mask)
# model = HyperGCN(in_dim=x.size(1), hid_dim=64, out_dim=num_classes)
# train(model, data)

# Added: test loop and full train+test pipeline

def test(model, data):
    model.eval()
    x, hyperedge_index = data.x, data.hyperedge_index
    out = model(x, hyperedge_index)
    pred = out.argmax(dim=1)
    acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean().item()
    print(f"Test Accuracy: {acc:.4f}")
    return acc

# Example full usage:
# data = Data(x=x, y=y, hyperedge_index=edge_index, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)
# model = HyperGCN(in_dim=x.size(1), hid_dim=64, out_dim=num_classes)
# train(model, data, epochs=200)
# test(model, data)

# ------------------ HyperGCL-style Contrastive + Supervised Training ------------------
import torch.nn.functional as F
from torch_geometric.nn import global_mean_pool


def nt_xent_loss(z1: Tensor, z2: Tensor, temperature: float = 0.5) -> Tensor:
    """Normalized temperature-scaled cross entropy loss for sets of graph embeddings.
    z1, z2: [batch, dim] (here batch = number of graphs/views; for node-level contrastive you would adapt)
    We compute contrastive loss pairing i in z1 with i in z2 (positive), others negative.
    """
    z1 = F.normalize(z1, p=2, dim=1)
    z2 = F.normalize(z2, p=2, dim=1)
    batch_size = z1.size(0)

    representations = torch.cat([z1, z2], dim=0)  # [2B, D]
    sim_matrix = torch.matmul(representations, representations.t())  # [2B,2B]
    sim_matrix = sim_matrix / temperature

    # mask out self-similarities
    mask = (~torch.eye(2 * batch_size, dtype=torch.bool, device=sim_matrix.device)).float()
    exp_sim = torch.exp(sim_matrix) * mask

    # positive pairs: i with i+B and i+B with i
    pos_sim = torch.exp(torch.sum(z1 * z2, dim=-1) / temperature)
    pos = torch.cat([pos_sim, pos_sim], dim=0)

    denom = exp_sim.sum(dim=1)
    loss = -torch.log(pos / denom)
    return loss.mean()


class HyperGCLTrainer:
    def __init__(self, model, aug_module, lr=1e-3, temperature=0.5, alpha=1.0, device='cpu'):
        """alpha: weight for supervised loss; contrastive weight = 1.0 by default"""
        self.model = model.to(device)
        self.aug = aug_module
        self.opt = torch.optim.Adam(self.model.parameters(), lr=lr)
        self.temperature = temperature
        self.alpha = alpha
        self.device = device

    def graph_repr(self, data: Data) -> Tensor:
        """Get graph-level representation by mean pooling node embeddings.
        Assumes single hypergraph per Data object.
        """
        self.model.eval()
        x = data.x.to(self.device)
        he = data.hyperedge_index.to(self.device)
        h = self.model(x, he)  # node embeddings
        # create a fake batch index all zeros (single graph) when pooling
        batch_index = torch.zeros(h.size(0), dtype=torch.long, device=h.device)
        g = global_mean_pool(h, batch_index)
        return h, g

    def train_one_epoch(self, data: Data, aug_params1, aug_params2):
        self.model.train()
        # create two augmented views
        v1, v2 = self.aug.make_two_views(data, aug_params1, aug_params2)
        # move to device
        v1.x = v1.x.to(self.device); v1.hyperedge_index = v1.hyperedge_index.to(self.device)
        v2.x = v2.x.to(self.device); v2.hyperedge_index = v2.hyperedge_index.to(self.device)

        # forward
        h1 = self.model(v1.x, v1.hyperedge_index)
        h2 = self.model(v2.x, v2.hyperedge_index)

        # graph-level embeddings (mean pool)
        batch1 = torch.zeros(h1.size(0), dtype=torch.long, device=h1.device)
        batch2 = torch.zeros(h2.size(0), dtype=torch.long, device=h2.device)
        g1 = global_mean_pool(h1, batch1)
        g2 = global_mean_pool(h2, batch2)

        # contrastive loss (between g1 and g2)
        contrastive_loss = nt_xent_loss(g1, g2, temperature=self.temperature)

        # supervised loss on original nodes (use original data labels)
        out = self.model(data.x.to(self.device), data.hyperedge_index.to(self.device))
        sup_loss = F.cross_entropy(out[data.train_mask.to(self.device)], data.y[data.train_mask].to(self.device))

        loss = contrastive_loss + self.alpha * sup_loss

        self.opt.zero_grad()
        loss.backward()
        self.opt.step()

        return loss.item(), contrastive_loss.item(), sup_loss.item()

    def validate(self, data: Data):
        self.model.eval()
        out = self.model(data.x.to(self.device), data.hyperedge_index.to(self.device))
        preds = out.argmax(dim=1)
        val_acc = (preds[data.val_mask.to(self.device)] == data.y[data.val_mask].to(self.device)).float().mean().item()
        return val_acc

    def test(self, data: Data):
        self.model.eval()
        out = self.model(data.x.to(self.device), data.hyperedge_index.to(self.device))
        preds = out.argmax(dim=1)
        test_acc = (preds[data.test_mask.to(self.device)] == data.y[data.test_mask].to(self.device)).float().mean().item()
        return test_acc


def run_training(model, data, aug_module, epochs=200, lr=1e-3, temperature=0.5, alpha=1.0, device='cpu'):
    trainer = HyperGCLTrainer(model, aug_module, lr=lr, temperature=temperature, alpha=alpha, device=device)

    # example augmentation pipelines (you can customize)
    aug1 = [('node_drop', {'drop_prob':0.2}), ('feature_mask', {'mask_prob':0.1})]
    aug2 = [('hyperedge_drop', {'drop_prob':0.3}), ('hyperedge_perturbation', {'add_ratio':0.05, 'remove_ratio':0.1})]

    best_val = 0.0
    best_model_state = None
    for epoch in range(1, epochs + 1):
        loss, cl_loss, sup_loss = trainer.train_one_epoch(data, aug1, aug2)
        if epoch % 10 == 0:
            val_acc = trainer.validate(data)
            print(f"Epoch {epoch:03d} | Loss {loss:.4f} | CL {cl_loss:.4f} | Sup {sup_loss:.4f} | ValAcc {val_acc:.4f}")
            if val_acc > best_val:
                best_val = val_acc
                best_model_state = {k: v.cpu() for k, v in trainer.model.state_dict().items()}

    # load best model and test
    if best_model_state is not None:
        trainer.model.load_state_dict(best_model_state)
    test_acc = trainer.test(data)
    print(f"Test Accuracy: {test_acc:.4f} | Best Val: {best_val:.4f}")
    return trainer.model

# End of HyperGCL-style training pipeline






import torch
from torch_geometric.data import HeteroData

# ==========================
# 1️⃣ Tạo HeteroGraphData với multi-edges
# ==========================
data = HeteroData()

# Node features
data['node'].x = torch.tensor([[1.0, 0.5],  # node 0
                               [0.2, 1.5],  # node 1
                               [0.0, 0.1]]) # node 2

# Multi-edges: 0->1 (3 edges), 1->2 (2 edges)
edge_index = torch.tensor([
    [0, 0, 0, 1, 1],  # src
    [1, 1, 1, 2, 2]   # dst
])
edge_attr = torch.tensor([
    [1.0, 0.0],  # edge 0
    [0.5, 0.5],  # edge 1
    [0.0, 1.0],  # edge 2
    [1.0, 1.0],  # edge 3
    [0.0, 2.0]   # edge 4
])

data['node', 'to', 'node'].edge_index = edge_index
data['node', 'to', 'node'].edge_attr = edge_attr

# Reverse edges
data['node', 'rev_to', 'node'].edge_index = edge_index.flipud()
data['node', 'rev_to', 'node'].edge_attr = edge_attr.clone()

# ==========================
# 2️⃣ Flatten edge mapping
# ==========================
def find_parallel_edges(edge_index):
    simplified_edge_mapping = {}
    simplified_edge_batch = []
    i = 0
    for edge in edge_index.T:
        tuple_edge = tuple(edge.tolist())
        if tuple_edge not in simplified_edge_mapping:
            simplified_edge_mapping[tuple_edge] = i
            i += 1
        simplified_edge_batch.append(simplified_edge_mapping[tuple_edge])
    return torch.LongTensor(simplified_edge_batch)

simp_edge_batch = find_parallel_edges(edge_index)

# Gán vào graph
data['node', 'to', 'node'].simp_edge_batch = simp_edge_batch
data['node', 'rev_to', 'node'].simp_edge_batch = simp_edge_batch

print("simp_edge_batch:", simp_edge_batch)

# ==========================
# 3️⃣ Flatten edge features (sum pooling)
# ==========================
def flatten_edge_features(edge_attr, simp_edge_batch):
    num_flattened_edges = simp_edge_batch.max().item() + 1
    flattened_edge_attr = torch.zeros((num_flattened_edges, edge_attr.size(1)))
    for i in range(num_flattened_edges):
        mask = simp_edge_batch == i
        flattened_edge_attr[i] = edge_attr[mask].sum(dim=0)
    return flattened_edge_attr

flat_attr_to = flatten_edge_features(data['node', 'to', 'node'].edge_attr,
                                     data['node', 'to', 'node'].simp_edge_batch)
flat_attr_rev = flatten_edge_features(data['node', 'rev_to', 'node'].edge_attr,
                                     data['node', 'rev_to', 'node'].simp_edge_batch)

print("Flattened edge features (to):\n", flat_attr_to)
print("Flattened edge features (rev):\n", flat_attr_rev)

# ==========================
# 4️⃣ Kết quả
# ==========================
# Edge 0->1: 3 multi-edges -> sum
# Edge 1->2: 2 multi-edges -> sum




import re

def analyze_text(text,
                 max_numbers=3,
                 max_english_words=5,
                 max_brackets=4):
    """
    Kiểm tra câu xem có quá nhiều số, từ tiếng Anh, hoặc dấu ngoặc.
    """
    # ---- Đếm số ----
    numbers = re.findall(r'\d+(\.\d+)?', text)
    num_count = len(numbers)

    # ---- Đếm từ tiếng Anh ----
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    eng_count = len(english_words)

    # ---- Đếm dấu ngoặc ----
    brackets = re.findall(r'[()\[\]{}]', text)
    br_count = len(brackets)

    # ---- Tạo thông báo ----
    messages = []

    if num_count > max_numbers:
        messages.append("Quá nhiều số")

    if eng_count > max_english_words:
        messages.append("Quá nhiều từ tiếng Anh")

    if br_count > max_brackets:
        messages.append("Quá nhiều dấu ngoặc")

    # Nếu không có gì bất thường
    if not messages:
        return "Bình thường"

    # Ghép thông báo
    return ", ".join(messages)


# ---- Ví dụ ----
texts = [
    "Giá là 3 (lần), thêm 2 (option) và 5 [more] items",
    "This is a test (a) (b) (c) (d) (e)",
    "Hôm nay có 2 quả táo thôi",
    "I bought 3 apples, 2 bananas and {one} more item"
]

for t in texts:
    print(f"'{t}' -> {analyze_text(t)}")





import re

def analyze_text(text, max_numbers=3, max_english_words=5):
    """
    Kiểm tra một câu xem có quá nhiều số hoặc quá nhiều từ tiếng Anh không.
    
    Args:
        text (str): Câu cần kiểm tra
        max_numbers (int): Ngưỡng tối đa số lượng số
        max_english_words (int): Ngưỡng tối đa số lượng từ tiếng Anh
    
    Returns:
        str: Thông báo tình trạng câu
    """
    # Đếm số
    numbers = re.findall(r'\d+(\.\d+)?', text)
    num_count = len(numbers)
    
    # Đếm từ tiếng Anh
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    eng_count = len(english_words)
    
    # Kiểm tra ngưỡng
    if num_count > max_numbers and eng_count > max_english_words:
        return "Quá nhiều số và quá nhiều từ tiếng Anh"
    elif num_count > max_numbers:
        return "Quá nhiều số"
    elif eng_count > max_english_words:
        return "Quá nhiều từ tiếng Anh"
    else:
        return "Bình thường"

# Ví dụ sử dụng
texts = [
    "Hôm nay tôi mua 3 apples, 2 oranges và 5 bananas giá 10 USD",
    "Chỉ có 2 quả táo",
    "I love Python programming and AI"
]

for t in texts:
    print(f"'{t}' -> {analyze_text(t)}")





# train_whisper_v3.py
import os
import torch
import numpy as np
import soundfile as sf
from datasets import load_dataset, Audio
from transformers import (
    WhisperForConditionalGeneration,
    WhisperProcessor,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer
)
import evaluate
from dataclasses import dataclass
from typing import Any, Dict, List

# --- config ----------------------------------------------------------------------------
MODEL = "openai/whisper-large-v3"
TRAIN_CSV = "dataset_whisper/train.csv"
VALID_CSV = "dataset_whisper/valid.csv"
OUTPUT_DIR = "whisper_ft_v3"
BATCH_SIZE = 4
EPOCHS = 3
LEARNING_RATE = 1e-5
# ---------------------------------------------------------------------------------------

# processor + model
processor = WhisperProcessor.from_pretrained(MODEL)
model = WhisperForConditionalGeneration.from_pretrained(MODEL)

# set language + task
model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(
    language="vi", task="transcribe"
)
model.config.suppress_tokens = []

model.to("cuda")

# load datasets
data_files = {"train": TRAIN_CSV, "validation": VALID_CSV}
ds = load_dataset("csv", data_files=data_files)

# Cast audio column
ds = ds.cast_column("path", Audio(sampling_rate=16000))

# preprocess
def preprocess(batch):
    audio = batch["path"]["array"]
    # extract features
    inputs = processor(audio, sampling_rate=16000, return_tensors="pt")
    input_features = inputs.input_features[0]

    # tokenize labels
    with processor.as_target_processor():
        labels = processor(batch["text"]).input_ids

    return {"input_features": input_features, "labels": labels}

ds["train"] = ds["train"].map(preprocess)
ds["validation"] = ds["validation"].map(preprocess)

# collator
@dataclass
class DataCollatorSpeechSeq2Seq:
    processor: WhisperProcessor
    def __call__(self, features):
        input_features = torch.stack([torch.tensor(f["input_features"]) for f in features])
        labels = [f["labels"] for f in features]

        labels_batch = self.processor.tokenizer.pad(
            {"input_ids": labels}, padding=True, return_tensors="pt"
        ).input_ids
        labels_batch[labels_batch == self.processor.tokenizer.pad_token_id] = -100

        return {"input_features": input_features, "labels": labels_batch}

data_collator = DataCollatorSpeechSeq2Seq(processor)

# training args
training_args = Seq2SeqTrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=4,
    fp16=True,
    num_train_epochs=EPOCHS,
    learning_rate=LEARNING_RATE,
    logging_steps=50,
    save_total_limit=2,
    evaluation_strategy="steps",
    eval_steps=200,
    save_steps=200,
    predict_with_generate=True,
    remove_unused_columns=False
)

# WER metric
wer_metric = evaluate.load("wer")

def compute_metrics(pred):
    label_ids = pred.label_ids
    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id
    pred_str = processor.tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)
    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)
    return {"wer": wer_metric.compute(predictions=pred_str, references=label_str)}

# trainer
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=ds["train"],
    eval_dataset=ds["validation"],
    data_collator=data_collator,
    tokenizer=processor.feature_extractor,
    compute_metrics=compute_metrics,
)

if __name__ == "__main__":
    trainer.train()
    trainer.save_model(OUTPUT_DIR)








# train_whisper_v3.py
import os
import torch
import numpy as np
import soundfile as sf
from datasets import load_dataset
from transformers import (
    WhisperForConditionalGeneration,
    WhisperProcessor,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer
)
import evaluate
from dataclasses import dataclass
from typing import Any, Dict, List

# --- config ----------------------------------------------------------------------------
MODEL = "openai/whisper-large-v3"
DATASET_CSV = "data/manifest.csv"       # columns: path,text
OUTPUT_DIR = "whisper_ft_v3"
BATCH_SIZE = 4
EPOCHS = 3
LEARNING_RATE = 1e-5
# ---------------------------------------------------------------------------------------

processor = WhisperProcessor.from_pretrained(MODEL)
model = WhisperForConditionalGeneration.from_pretrained(MODEL)

# set language + task → BẮT BUỘC
model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(
    language="vi", task="transcribe"
)
model.config.suppress_tokens = []

model.to("cuda")

# load dataset
ds = load_dataset("csv", data_files={"train": DATASET_CSV})["train"]

# load audio
def load_audio(ex):
    speech, sr = sf.read(ex["path"])
    ex["audio"] = {"array": speech, "sampling_rate": sr}
    return ex

ds = ds.map(load_audio)

# preprocess fn
def preprocess(batch):
    audio = batch["audio"]

    # Whisper yêu cầu 16kHz
    if audio["sampling_rate"] != 16000:
        raise ValueError("Audio must be 16kHz. Resample first!")

    # extract log-mel
    features = processor(
        audio=audio["array"],
        sampling_rate=16000,
        return_tensors="pt"
    ).input_features[0]

    # tokenize text
    with processor.as_target_processor():
        labels = processor(batch["text"]).input_ids

    return {"input_features": features, "labels": labels}

ds = ds.map(preprocess, remove_columns=ds.column_names)

# collator
@dataclass
class DataCollatorSpeechSeq2Seq:
    processor: WhisperProcessor
    def __call__(self, features):
        input_features = torch.stack([torch.tensor(f["input_features"]) for f in features])
        labels = [f["labels"] for f in features]

        labels_batch = self.processor.tokenizer.pad(
            {"input_ids": labels}, 
            padding=True, 
            return_tensors="pt"
        ).input_ids

        labels_batch[labels_batch == self.processor.tokenizer.pad_token_id] = -100

        return {
            "input_features": input_features,
            "labels": labels_batch
        }

data_collator = DataCollatorSpeechSeq2Seq(processor)

# training args
training_args = Seq2SeqTrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=4,
    fp16=True,
    num_train_epochs=EPOCHS,
    learning_rate=LEARNING_RATE,
    logging_steps=50,
    save_total_limit=2,
    evaluation_strategy="no",
    remove_unused_columns=False
)

# WER metric
wer = evaluate.load("wer")

def compute_metrics(pred):
    pred_ids = pred.predictions
    label_ids = pred.label_ids

    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id

    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)

    return {"wer": wer.compute(predictions=pred_str, references=label_str)}

# trainer
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=ds,
    data_collator=data_collator,
    tokenizer=processor.feature_extractor,
    compute_metrics=compute_metrics,
)

if __name__ == "__main__":
    trainer.train()
    trainer.save_model(OUTPUT_DIR)





import torch
from torch import nn
import inspect
from torch_geometric.nn.aggr import Aggregation
from torch_geometric.nn import MessagePassing
from torch_geometric.data import Data

# ---------------- MLPAutoencoder ----------------
class MLPAutoencoder(nn.Module):
    """
    Simple MLP Autoencoder: encode → latent → decode
    """
    def __init__(self, layer_sizes=(1, 2, 2, 4)):
        super().__init__()
        # Encoder
        enc_layers = []
        for i in range(len(layer_sizes) - 1):
            enc_layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))
            enc_layers.append(nn.ReLU())
        self.encoder = nn.Sequential(*enc_layers[:-1])  # remove last ReLU

        # Decoder (mirror of encoder)
        dec_layers = []
        rev_sizes = list(layer_sizes[::-1])
        for i in range(len(rev_sizes) - 1):
            dec_layers.append(nn.Linear(rev_sizes[i], rev_sizes[i+1]))
            dec_layers.append(nn.ReLU())
        self.decoder = nn.Sequential(*dec_layers[:-1])

    def forward(self, x):
        return self.encoder(x)

    def inverse(self, z):
        return self.decoder(z)

    def reset_parameters(self):
        for layer in self.encoder:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                nn.init.zeros_(layer.bias)
        for layer in self.decoder:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_uniform_(layer.weight)
                nn.init.zeros_(layer.bias)


# ---------------- GenAgg ----------------
class GenAgg(Aggregation):
    """
    Generalized Aggregation using learnable MLP Autoencoder
    """
    def __init__(self, f=None, a=None, b=None, **kwargs):
        super().__init__()
        if f is None:
            self.f = MLPAutoencoder(layer_sizes=(1, 2, 2, 4))
        elif inspect.isclass(f):
            self.f = f(**kwargs)
        else:
            self.f = f

        self.a = nn.Parameter(torch.tensor(0.0)) if a is None else a
        self.b = nn.Parameter(torch.tensor(0.0)) if b is None else b

    def reset_parameters(self):
        nn.init.zeros_(self.a)
        nn.init.zeros_(self.b)
        if hasattr(self.f, 'reset_parameters'):
            self.f.reset_parameters()

    def get_n(self, x, index=None, ptr=None, dim_size=None, dim=-2):
        n = self.reduce(torch.ones_like(x), index, ptr, dim_size, dim, reduce='sum')
        n[n==0] = 1
        return n

    def forward(self, x, index=None, ptr=None, dim_size=None, dim=-2):
        if isinstance(self.b, nn.Parameter) or self.b != 0:
            x_mean = self.reduce(x, index, ptr, dim_size, dim, reduce='mean')
            if index is None:
                x = x - self.b * x_mean.unsqueeze(dim)
            else:
                x = x - self.b * torch.index_select(input=x_mean, dim=dim, index=index)

        n = self.get_n(x=x, index=index, ptr=ptr, dim_size=dim_size, dim=dim)
        x = x.unsqueeze(-1)
        n = n.unsqueeze(-1)
        if dim < 0:
            dim -= 1

        y1 = self.f.forward(x)
        y2 = self.reduce(y1, index, ptr, dim_size, dim, reduce='mean')
        y3 = y2 * (n**self.a)
        z = self.f.inverse(y3)
        z = z.squeeze(-1)

        return z

    def dist_op(self, a, b, type=1):
        if type == 1:
            return self.f.inverse(self.f.forward(a) * self.f.forward(b))
        elif type == 0:
            return self.f.inverse(self.f.forward(a) + self.f.forward(b))


# ---------------- Example: Message Passing GNN using GenAgg ----------------
class GenAggGNN(MessagePassing):
    def __init__(self, in_channels, out_channels):
        super().__init__(aggr=GenAgg())  # dùng GenAgg aggregator
        self.lin = nn.Linear(in_channels, out_channels)

    def forward(self, x, edge_index):
        out = self.propagate(edge_index, x=x)
        out = self.lin(out)
        return out

    def message(self, x_j):
        return x_j

    def update(self, aggr_out):
        return aggr_out


# ---------------- Example usage ----------------
if __name__ == "__main__":
    # Create a small graph: 3 nodes, 4 edges
    edge_index = torch.tensor([[0, 1, 2, 0],
                               [1, 0, 0, 2]], dtype=torch.long)

    x = torch.randn(3, 5)  # 3 nodes, 5 features
    data = Data(x=x, edge_index=edge_index)

    # Initialize GNN
    model = GenAggGNN(in_channels=5, out_channels=4)

    # Forward
    out = model(data.x, data.edge_index)
    print("Output node features:", out)
    print("Shape:", out.shape)






import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
from captum.attr import IntegratedGradients
import matplotlib.pyplot as plt
import numpy as np
import random, os

# -----------------------------
# 1️⃣ SETUP
# -----------------------------
torch.manual_seed(42)
random.seed(42)
np.random.seed(42)

input_dim = 20
hidden_dim = 32
num_classes = 3
num_samples = 500
batch_size = 32
epochs = 15
log_dir = "runs/model_interpret_full"

os.makedirs(log_dir, exist_ok=True)
writer = SummaryWriter(log_dir=log_dir)

# -----------------------------
# 2️⃣ DATA: random cho dễ nhìn
# -----------------------------
X = torch.randn(num_samples, 10, input_dim)  # (batch, seq, features)
y = torch.randint(0, num_classes, (num_samples,))

dataset = TensorDataset(X, y)
loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# -----------------------------
# 3️⃣ MODEL: LSTM cơ bản
# -----------------------------
class InterpretableLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        h, _ = self.lstm(x)
        out = self.relu(h[:, -1, :])  # lấy hidden cuối
        logits = self.fc(out)
        return logits, {"hidden": h, "activation": out}

model = InterpretableLSTM(input_dim, hidden_dim, num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# -----------------------------
# 4️⃣ TRAIN LOOP + LOG
# -----------------------------
for epoch in range(epochs):
    model.train()
    total_loss, correct = 0, 0

    for batch_X, batch_y in loader:
        optimizer.zero_grad()
        logits, internals = model(batch_X)
        loss = criterion(logits, batch_y)
        loss.backward()

        optimizer.step()

        total_loss += loss.item()
        correct += (logits.argmax(1) == batch_y).sum().item()

        # Log histograms
        for name, param in model.named_parameters():
            writer.add_histogram(f"weights/{name}", param, epoch)
            if param.grad is not None:
                writer.add_histogram(f"grads/{name}", param.grad, epoch)

        # Log activation stats
        writer.add_histogram("activations/last_hidden", internals["activation"], epoch)

    acc = correct / len(dataset)
    avg_loss = total_loss / len(loader)
    writer.add_scalar("Loss/train", avg_loss, epoch)
    writer.add_scalar("Accuracy/train", acc, epoch)

    print(f"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Acc: {acc:.3f}")

# -----------------------------
# 5️⃣ EMBEDDING PROJECTOR
# -----------------------------
embeddings = []
labels = []
with torch.no_grad():
    for Xb, yb in loader:
        logits, internals = model(Xb)
        embeddings.append(internals["activation"])
        labels.append(yb)
embeddings = torch.cat(embeddings)
labels = torch.cat(labels)
writer.add_embedding(embeddings, metadata=labels, tag="embedding_space")

# -----------------------------
# 6️⃣ FEATURE IMPORTANCE (Captum)
# -----------------------------
ig = IntegratedGradients(model)
model.eval()
sample_X = X[0:1]
sample_y = y[0:1]
attr, delta = ig.attribute(sample_X, target=sample_y.item(), return_convergence_delta=True)

# Vẽ heatmap thể hiện importance theo chiều thời gian + feature
attr_np = attr.squeeze(0).detach().numpy()
plt.figure(figsize=(8, 4))
plt.imshow(attr_np.T, cmap="hot", aspect="auto")
plt.colorbar(label="Feature importance")
plt.title("Integrated Gradients Heatmap (Captum)")
plt.xlabel("Time step")
plt.ylabel("Feature dim")
plt.tight_layout()
plt.savefig(os.path.join(log_dir, "feature_importance_heatmap.png"))
plt.close()

writer.close()
print("✅ Training done. Logs saved to:", log_dir)
print("Run TensorBoard: tensorboard --logdir runs/model_interpret_full")









import torch
import matplotlib.pyplot as plt

# ============================================================
# 1️⃣ Tạo ma trận HiPPO-LegS (A, B)
# ============================================================
def hippo_legs_matrix(N: int):
    """Tạo ma trận A, B cho HiPPO-LegS"""
    n = torch.arange(N, dtype=torch.float32)
    A = torch.zeros((N, N))
    for i in range(N):
        for j in range(N):
            if j <= i:
                A[i, j] = -(2 * i + 1) * ((-1) ** (i - j))
    B = (2 * n + 1).sqrt().unsqueeze(-1)
    return A, B

# ============================================================
# 2️⃣ Rời rạc hóa bằng Bilinear transform (Tustin)
# ============================================================
def bilinear_discretize(A, B, dt=0.01):
    I = torch.eye(A.size(0))
    Ad = (I + 0.5 * dt * A) @ torch.linalg.inv(I - 0.5 * dt * A)
    Bd = torch.linalg.inv(I - 0.5 * dt * A) @ B * dt
    return Ad, Bd

# ============================================================
# 3️⃣ Mô phỏng HiPPO với tín hiệu x(t) = t
# ============================================================
def simulate_hippo(N=4, T=1.0, dt=0.01):
    steps = int(T / dt)
    A, B = hippo_legs_matrix(N)
    Ad, Bd = bilinear_discretize(A, B, dt)

    c = torch.zeros(N, 1)
    states = [c.clone()]
    xs = []
    ts = []

    for step in range(steps):
        t = step * dt
        x_t = torch.tensor([t])  # x(t) = t
        c = Ad @ c + Bd * x_t
        states.append(c.clone())
        xs.append(x_t.item())
        ts.append(t)

    states = torch.cat(states, dim=1)
    return ts, xs, states

# ============================================================
# 4️⃣ Vẽ kết quả
# ============================================================
ts, xs, states = simulate_hippo(N=4, T=1.0, dt=0.01)

plt.figure(figsize=(10, 6))
for i in range(states.size(0)):
    plt.plot(ts, states[i, 1:].numpy(), label=f'c[{i}]')

plt.title("Tiến hóa hệ số HiPPO-LegS cho x(t)=t")
plt.xlabel("Thời gian t")
plt.ylabel("Giá trị hệ số c_i(t)")
plt.legend()
plt.grid(True)
plt.show()





import pandas as pd
import numpy as np

INPUT = "NF-ToN-IoT-v2_1M_balanced.csv"
OUTPUT = "NF-ToN-IoT-v2_1M_balanced_shuffled.csv"
CHUNK_SIZE = 100_000
RANDOM_STATE = 1234

# 1. Đọc file thành từng khối
chunks = pd.read_csv(INPUT, chunksize=CHUNK_SIZE)

# 2. Shuffle thứ tự các khối
chunks = list(chunks)
np.random.seed(RANDOM_STATE)
np.random.shuffle(chunks)

# 3. Shuffle trong từng khối (ít tốn RAM)
for i, chunk in enumerate(chunks):
    chunk = chunk.sample(frac=1.0, random_state=RANDOM_STATE + i)
    mode = "w" if i == 0 else "a"
    header = (i == 0)
    chunk.to_csv(OUTPUT, index=False, mode=mode, header=header)

print("✅ Đã shuffle toàn bộ và lưu:", OUTPUT)




import pandas as pd
import numpy as np

# ==============================================================
# ⚙️ CẤU HÌNH
# ==============================================================
INPUT = "NF-ToN-IoT-v2_100k.csv"           # file đầu vào
OUTPUT = "NF-ToN-IoT-v2_100k_clean.csv"    # file sau khi làm sạch
CLIP_MIN, CLIP_MAX = -1e6, 1e6             # giới hạn giá trị cực trị

# ==============================================================
# 1️⃣ Đọc dữ liệu
# ==============================================================
df = pd.read_csv(INPUT)
print("📊 Kích thước ban đầu:", df.shape)

if 'Attack' not in df.columns:
    raise ValueError("❌ Không tìm thấy cột 'Attack' trong file CSV.")

# ==============================================================
# 2️⃣ Xử lý NaN
# ==============================================================
# Xoá dòng không có nhãn Attack
df = df.dropna(subset=['Attack']).reset_index(drop=True)

# Xác định cột số và cột chuỗi
num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_cols = df.select_dtypes(include=['object']).columns.drop('Attack').tolist()

# Điền giá trị thiếu
for col in num_cols:
    df[col] = df[col].fillna(df[col].median())

for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

print(f"✅ Đã xử lý NaN: {len(num_cols)} cột số, {len(cat_cols)} cột chuỗi.")

# ==============================================================
# 3️⃣ Giới hạn (clip) giá trị cực trị
# ==============================================================
df[num_cols] = df[num_cols].clip(lower=CLIP_MIN, upper=CLIP_MAX)
print(f"✅ Đã giới hạn giá trị trong khoảng [{CLIP_MIN}, {CLIP_MAX}]")

# ==============================================================
# 4️⃣ Lưu dữ liệu sạch
# ==============================================================
df.to_csv(OUTPUT, index=False)
print("✅ Đã lưu file làm sạch:", OUTPUT)





import pandas as pd
from sklearn.utils import resample

INPUT = "NF-ToN-IoT-v2.csv"
OUTPUT = "NF-ToN-IoT-v2_1M_balanced.csv"
TARGET_TOTAL = 1_000_000
RANDOM_STATE = 1234

df = pd.read_csv(INPUT)

if 'Attack' not in df.columns:
    raise ValueError("File CSV không có cột 'Attack'")

classes = df['Attack'].unique()
num_classes = len(classes)
target_per_class = TARGET_TOTAL // num_classes
remainder = TARGET_TOTAL % num_classes

sampled_parts = []
for i, cls in enumerate(sorted(classes)):
    cls_df = df[df['Attack'] == cls]
    this_target = target_per_class + (1 if i < remainder else 0)
    part = cls_df.sample(
        n=this_target,
        replace=(len(cls_df) < this_target),
        random_state=RANDOM_STATE,
    ).sample(frac=1.0, random_state=RANDOM_STATE)  # shuffle riêng từng lớp
    sampled_parts.append(part)

# concat mà không shuffle toàn cục
df_balanced = pd.concat(sampled_parts, ignore_index=True)

print(df_balanced['Attack'].value_counts())

df_balanced.to_csv(OUTPUT, index=False)
print("Saved to:", OUTPUT)





